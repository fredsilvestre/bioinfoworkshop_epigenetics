---
title: "DNA methylation workflow - workshop 2026 part3"
author: "Frederic Silvestre"
date: "09/02/2026"
output: html_document
---

This part3 of the DNA methylation workflow aims to work on real RAW data obtained after RRBS bisulfite sequencing using an Ilumina sequencer. The data consists in 6 libraries of mangrove rivulus brain sampled in 2019 in two wild population: EPP (Emerson Point Preserve in Florida ; TC (Twin Cayes in Belize).

ID of fish from Twin Caye: Brain 2, 3, 4
ID of fish from EPP: Brain 69, 71, 73

The RAW files are in the file "fastq" with the name "BrainX.fastq.gz"

For the scientific background, see the presentation.



# 0° Preparation of the working environment


```{r eval=T}
setwd("/Users/fsilvest/Dropbox/studentpack_2026") # adapt to your computer
getwd()

ls()
rm(list = ls())

#tempdir() #where to save temporary data from R
#list.files(tempdir())

#unlink(tempdir(), recursive = TRUE) # To clean the tempdir. The temp directory usually cleans itself up when you close R. Only use this if you're experiencing specific issues with temp files, and always restart R immediately afterward

#dev.list()
#dev.off() #to reset the graph device options

```


```{r}
#if (!require("stringi", quietly = TRUE)) {
#      install.packages("stringi",type="mac.binary") 
#      library(stringi)}

#mac.binary > if an error message appears (aucun package nommé ‘stringi’ n'est trouvé)

bioc_packages <- c("GenomicRanges", "GenomeInfoDb", "IRanges", "Biostrings", "BSgenome", "AnnotationHub", "GenomicFeatures", "SGSeq", "qvalue", "pwalign", "methylKit", "ShortRead","genomation", "remotes", "txdbmaker", "fastqcr", "Rqc", "QuasR", "methylKit")  

cran_packages <- c("knitr","factoextra", "gridExtra", "ggplot2", "psych", "diptest", "MASS", "pheatmap")


for (pkg in bioc_packages) {
    if (!requireNamespace(pkg, quietly = TRUE)) {
        BiocManager::install(pkg, ask = FALSE)
    }
    library(pkg, character.only = TRUE)
}


for (pkg in cran_packages) {
    if (!requireNamespace(pkg, quietly = TRUE)) {
        install.packages(pkg, dependencies = TRUE)
    }
    library(pkg, character.only = TRUE)
}

```



# 1° Quality check

Working with FastQ files
Usually, we work with FastQC (https://www.bioinformatics.babraham.ac.uk/projects/fastqc/) or multiqc (https://seqera.io/multiqc/)

In the Terminal:
pip install multiqc
# or
pip3 install multiqc


```{r results=markup}
#to verify if the image exists and the full pathway
file.exists("images/Phred.png")
normalizePath("images/Phred.png")

```

![Phred values](/Users/fsilvest/Library/CloudStorage/Dropbox/studentpack_2026/images/Phred.png)

![FASTQ sequence](/Users/fsilvest/Library/CloudStorage/Dropbox/studentpack_2026/images/Phred2.png)


Example of quality check option using Rqc package.

In the package Rqc, we must load fastq.gz files. If we start from fasta.gz, we can convert it using the lines below from the package ShortRead.

```{r}
# Read fasta file
fasta_data <- readFasta("input.fasta.gz")

# Create quality scores
# Assign a uniform quality score (e.g., Phred score of 40, which is 'I')
quality_scores <- BStringSet(rep(paste(rep("I", width(fasta_data)[1]), collapse=""), 
                                 length(fasta_data)))

# Create ShortReadQ object (FASTQ format with quality)
fastq_data <- ShortReadQ(sread = sread(fasta_data),
                         quality = BStringSet(quality_scores),
                         id = id(fasta_data))

# Convert and write to FASTQ ; we need to add Phred scores.
writeFastq(fasta_data, "output.fastq.gz", compress=TRUE)

```



```{r results=markup}

folder <- system.file(package="ShortRead", "extdata/E-MTAB-1147") #example dataset
dir(folder)

vignette("Rqc")

qcRes <- rqc(path=folder, pattern=".fastq.gz", openBrowser=F)

perFileInformation(qcRes)

#saveRDS(qcRes, file="RAW_data_Florida_Belize/RDS/qcRes.RDS")
#qcRes <- readRDS("RAW_data_Florida_Belize/RDS/qcRes.RDS")
qcRes

rqcReadQualityBoxPlot(qcRes)
rqcReadQualityPlot(qcRes)
rqcCycleAverageQualityPlot(qcRes)
rqcReadFrequencyPlot(qcRes)
rqcCycleQualityPlot(qcRes)
rqcCycleAverageQualityPcaPlot(qcRes)
rqcCycleBaseCallsLinePlot(qcRes)

# we can run and save the analysis in a html report

#files <- list.files(folder, "fastq.gz", full.names=TRUE)
#qa <- rqcQA(files, workers=1)

#saveRDS(qa, file="RAW_data_Florida_Belize/RDS/qa.RDS")
#qa <- readRDS("RAW_data_Florida_Belize/RDS/qa.RDS")

#reportFile <- rqcReport(qa)
#saveRDS(reportFile, file="RAW_data_Florida_Belize/RDS/reportFile.RDS")
#readRDS("RAW_data_Florida_Belize/RDS/reportFile.RDS")
#browseURL(reportFile)
#system(paste("open", reportFile))  # For macOS
#print(reportFile)

```

**How to interpret the ReadFrequency graph ?**

Most Reads Appear Once

In a typical, high-complexity library, you expect a large proportion of reads to be unique (frequency = 1).
The bar or point at frequency = 1 is often the highest on the plot.
Reads with Higher Frequencies

If you see a significant spike in reads that appear 10, 50, or 100 times (etc.), it suggests duplication.
Moderate duplication (a small tail at higher frequencies) can be normal, especially in targeted sequencing (amplicon-based) or if your sample is highly expressed in certain transcripts.
Excessive Duplication

A large portion of reads with very high frequencies can indicate technical artifacts (PCR over-amplification, adapter contamination).
In severe cases, you might need to remove duplicates or improve library prep methods.


**Analyse the sequencing quality of the rivulus samples and compare the results to the example files above.**

```{r}

folderkm <- "RAW_data_Florida_Belize/fastq/" #real dataset
list.files(folderkm)

#qcReskm <- rqc(path=folderkm, pattern=".fastq.gz", openBrowser=FALSE) #takes time

#saveRDS(qcReskm, file="RAW_data_Florida_Belize/RDS/qcReskm.RDS")
qcReskm <- readRDS("RAW_data_Florida_Belize/RDS/qcReskm.RDS")
qcReskm

perFileInformation(qcReskm)

files <- list.files(folderkm, "fastq.gz", full.names=TRUE)
#qakm <- rqcQA(files, workers=1) #takes time
#qakm

#saveRDS(qakm, file="RAW_data_Florida_Belize/RDS/qakm.RDS")
qakm <- readRDS("RAW_data_Florida_Belize/RDS/qakm.RDS")

#analyze the quality of the 6 files
rqcReadQualityBoxPlot(qakm)
rqcReadQualityPlot(qakm)
rqcCycleAverageQualityPlot(qakm)
rqcReadFrequencyPlot(qakm)
rqcCycleQualityPlot(qakm)
rqcCycleBaseCallsLinePlot(qakm)

# > less C and more T
# first nucleotides different pattern

```

```{r}

# we can analyse a single sample and work on the sequence

#fq <- readFastq("RAW_data_Florida_Belize/fastq/Brain2.fastq.gz") #long time

#saveRDS(fq, file="RAW_data_Florida_Belize/RDS/fqBrain2.RDS")
fq <- readRDS("RAW_data_Florida_Belize/RDS/fqBrain2.RDS")

class(fq)
sequences <- sread(fq)
sequences
qfq <- quality(fq)
qfq
class(qfq)

qPerBase=as(quality(fq[1]), "matrix")
qPerBase
qcount=rowSums(qPerBase<=20)
qcount

```

Analyze the data with Fastqc or multiqc

To install FastQC from the Terminal:

# Install Homebrew if you don't have it
/bin/bash -c "$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)"

# Install FastQC
brew install fastqc

# Verify installation
fastqc --version **should be v0.12.1**

To install multiqc from the Terminal: brew install multiqc **version 1.33**
we can use: python3 -m multiqc --version **if multiqc is not working**

```{r}
files <- list.files(folderkm, "fastq.gz", full.names=TRUE)

Sys.which("fastqc")
Sys.which("multiqc") #if it gives "" > not installed or not the good location


# Run FastQC
dir.create("fastqc_output", showWarnings = FALSE)
system(paste("fastqc", paste(files, collapse = " "), "-o fastqc_output/")) #takes time

# Run MultiQC
system("python3 -m multiqc fastqc_output/ -o .")

# Open MultiQC report
browseURL("multiqc_report.html")

```



# 2° Filter and trim the reads

We must trim the reads to increase the quality to have a good alignment. For that, we usually use TRIM GALORE (which is using CUTADAPT)
	- remove adapters
	- remove low quality nucleotides (< 20)
	- remove the end-repaired C at the extremity (--rrbs)
	
To help installing Trim Galore ! : https://github.com/FelixKrueger/TrimGalore 
	
Alternatively, we can use QuasR but less good for RRBS.

```{r}

vignette("QuasR")

fastqFiles <- system.file(package="ShortRead",
                          "extdata/E-MTAB-1147",
                          c("ERR127302_1_subset.fastq.gz",
                            "ERR127302_2_subset.fastq.gz"))
outfiles <- paste(tempfile(pattern=c("processed_1_",
                                     "processed_2_")),".fastq", sep="")

?preprocessReads

preprocessReads(fastqFiles, outfiles,
                nBases=1,
                truncateEndBases=3,
                Lpattern="ACCCGGGA",
                minLength=40)



#with real samples (too long)
preprocessReads(filename = "RAW_data_Florida_Belize/fastq/Brain2.fastq.gz", outputFilename="RAW_data_Florida_Belize/fastq_trim/Brain2trimQuasR.fastq.gz", truncateEndBases= 2, nBases=0, minLength=40, Lpattern="AGATCGGAAGAG")

qcReskmtrim <- rqc(path="RAW_data_Florida_Belize/fastq_trim", pattern=".fastq.gz", openBrowser=FALSE) #takes time

perFileInformation(qcReskmtrim)

rqcReadQualityBoxPlot(qcReskmtrim)
rqcReadQualityPlot(qcReskmtrim)
rqcCycleAverageQualityPlot(qcReskmtrim)
rqcReadFrequencyPlot(qcReskmtrim)
rqcCycleQualityPlot(qcReskmtrim)
rqcCycleAverageQualityPcaPlot(qcReskmtrim)
rqcCycleBaseCallsLinePlot(qcReskmtrim)

files <- list.files("RAW_data_Florida_Belize/fastq_trim", "fastq.gz", full.names=TRUE)
qakm <- rqcQA(files, workers=1) #takes time
qakm

reportFilekm <- rqcReport(qakm)

browseURL(reportFilekm)

#Illumina univeral adaptor= AGATCGGAAGAG

```

The result of the trimming of Brain2 can be summarized here:

![Trim Brain2](/Users/fsilvest/Library/CloudStorage/Dropbox/studentpack_2026/images/tabletrimBrain2.png)

After trimming and quality control, we can align the sequences to the reference genome. For BiSeq, we use Bismark (which is using Bowtie2): https://www.bioinformatics.babraham.ac.uk/projects/bismark/ 

A reference genome assembly must be first downloaded. For rivulus, the last genome assembly (RefSeq assembly accession: GCF_001649575.2 ) can be found here: https://www.ncbi.nlm.nih.gov/data-hub/genome/GCF_001649575.2/

Then the genome must be prepared for RRBS before running Bismark with chosen options.

Example:

Prepare the genome for RRBS if we first use the genome:
/Applications/Bismark-0.22.3/bismark_genome_preparation --path_to_aligner /Applications/bowtie/bin/ --verbose ~/bioinformatic_workshop/RAW_data_Florida_Belize/Sequences/genomeDovetail/

-Run Bismark:
/Applications/Bismark-0.22.3/bismark --genome ~/bioinformatic_workshop/RAW_data_Florida_Belize/Sequences/genomeDovetail/ --score_min L,0,-0.6 --output_dir ~/bioinformatic_workshop/RAW_data_Florida_Belize/Bismark_output ~/bioinformatic_workshop/RAW_data_Florida_Belize/TrimGalore_output/Brain2_trimmed_simple_nondir.fq.gz

The output are sam.gz files that must first be uncompressed.
Bismark writes a report in .txt where we can find many infos such as the average % methylation.

We must first reorganize the  files after Bismark with the samtools package from the terminal.

Now we read a file from Bismark with the format .SAM
SAM files must be sorted by chromosome and read position columns, using ‘sort’ command in unix-like machines will accomplish such a sort easily. BAM files should be sorted and indexed. This could be achieved with samtools (http://www.htslib.org/doc/samtools.html).
Follow samtools tutorial: http://quinlanlab.org/tutorials/samtools/samtools.html#:~:text=samtools%20%E2%80%9Csort%E2%80%9D&text=In%20other%20words%2C%20the%20BAM,in%20the%20input%20FASTQ%20files.&text=Doing%20anything%20meaningful%20such%20as,occur%20in%20%E2%80%9Cgenome%20order%E2%80%9D.
List of terminal commands: https://www.makeuseof.com/tag/mac-terminal-commands-cheat-sheet/

cd ~
mkdir methylome
cd ~/methylome
git clone https://github.com/samtools/htslib
git clone https://github.com/samtools/samtools
cd samtools
make
!!!! to use a command while you are in the good directory: ./samtools
cd .. #to come back in methylome
./samtools/samtools view CTL1.bam| head

When you align FASTQ files with all current sequence aligners, the alignments produced are in random order with respect to their position in the reference genome. In other words, the BAM file is in the order that the sequences occurred in the input FASTQ files.

./samtools/samtools sort CTL1.bam -o CTL1.sorted.bam



# 3° Working in methylKit

## Importing the data in methylKit

Once the files are in .BAM format after Samtools, we can import them in methylKit package in R using processBismarkAln function.

We can now do it at once for several files (it takes 6-7min per file)
It's an object methylRawList of 6

The file has been saved in the txt file to save time: 2_CpG.txt, etc


```{r}

file.list <- list( "Brain2.sorted.bam", "Brain3.sorted.bam", "Brain4.sorted.bam","Brain69.sorted.bam", "Brain71.sorted.bam", "Brain73.sorted.bam")

#it takes a lot of time
myobj <- processBismarkAln(file.list,
           sample.id=list("TC1","TC2","TC3", "EPP1", "EPP2", "EPP3"),
           assembly="ASM164957v2",
           treatment=c(1,1,1,0,0,0),
           read.context="CpG",
           save.folder = getwd(),
           mincov = 10
           )

#characterize myobj
length(myobj)
class(myobj)
head(myobj)


file.list <- list("/RAW_data_Florida_Belize/txt/2_CpG.txt", "/RAW_data_Florida_Belize/txt/3_CpG.txt", "/RAW_data_Florida_Belize/txt/4_CpG.txt", "/RAW_data_Florida_Belize/txt/69_CpG.txt", "/RAW_data_Florida_Belize/txt/71_CpG.txt", "/RAW_data_Florida_Belize/txt/73_CpG.txt")

myobj <- methRead(file.list,
           sample.id=list("TC1","TC2","TC3", "EPP1", "EPP2", "EPP3"),
           assembly="ASM164957v2",
           treatment=c(1,1,1,0,0,0),
           context="CpG",
           mincov = 10
           )

saveRDS(myobj, file="/Users/fsilvestre/bioinformatic_workshop/RAW_data_Florida_Belize/RDS/TC-EPP.RDS")
myobj <- readRDS("RAW_data_Florida_Belize/RDS/TC-EPP.RDS")

myobj

```

Between 1 312 273 and 1 712 975 rows > CpG

## Analyse the CpG on each file and filter to get rid of the low quality

```{r}
#analyse the 6 graphs and extract the median values for each sample.

X
X
x
x
x
x
x
x
x
x
x
x
x
x


#extract the median values from the 4 objects
x
x
x
x
x
x
x
x
x
x
x

```


```{r}

#Get the 6 graphs for the coverage values

x
x
x
x
x
x
x
x
x
x
x
x
x
x
x

```


```{r}
#filter by coverage with lo.count = 10 and hi.perc=99.9
x
x
x
x
x
x
x
x
x
x
x

#we can be more stringent and take a min coverage of 20
x
x
x
x
x
x

#what are the differences between filtered by 10 or 20 ?

```





## Unite the different files in the same object

We can set a minimum number of samples covered min.per.group (1L, 2L, 3L)

```{r}

meth <- methylKit::unite(filtered.myobj, destrand=T, min.per.group = NULL)
meth

meth2L <- methylKit::unite(filtered.myobj, destrand=T, min.per.group = 2L)
meth2L

meth20 <- methylKit::unite(filtered.myobj20, destrand=T, min.per.group = NULL)
meth20

#compare the number of CpG analyzed with different parameters of min.per.group and coverage. What is the best option to chose ?

```
x
x
x


## Explore the variability of each CpG

```{r}

pm=percMethylation(meth) 
head(pm)
summary(pm)

#calculate the coefficient of variation for each CpG in TC and in EPP
CV <- function(x){sd(x)/mean(x)*100}

TC <- apply(pm[,1:3], MARGIN=1,FUN = CV)
head(TC)
summary(TC)
EPP <- apply(pm[,4:6], MARGIN=1,FUN = CV)
summary(EPP)
CVall <- apply(pm[,1:6], MARGIN=1,FUN = CV)
summary(CVall)

hist(CVall)

```
mean CV TC: 34.36
mean CV EPP: 29.78
mean CV all: 44.01


## PCA and clustering 

Only on a matrix with no NA (CpG in all samples)

```{r}

getCorrelation(meth,plot=F)

```

```{r}

clusterSamples(meth, dist="correlation", method="ward", plot=TRUE)

```

```{r}

pc <- PCASamples(meth,obj.return = T, adj.lim=c(1,1), comp = c(1,2))


# Eigenvalues
eig.val <- get_eigenvalue(pc)
eig.val
fviz_eig(pc)

```


**Perform Discriminant Analysis**

```{r}


# Get methylation percentage matrix
meth_matrix <- percMethylation(meth)

# Check dimensions
dim(meth_matrix)  # Should be: 691258 CpG sites × N samples

# Transpose so samples are rows (required for LDA)
meth_t <- t(meth_matrix)

# Check
dim(meth_t)  # Should be: N samples × 691258 CpG sites

# Calculate variance for each CpG site
cpg_variance <- apply(meth_matrix, 1, var, na.rm = TRUE)

# Keep top 1000 most variable CpGs
top_n <- 1000
top_cpgs <- order(cpg_variance, decreasing = TRUE)[1:top_n]

# Subset methylation data
meth_reduced <- meth_matrix[top_cpgs, ]

# Transpose for LDA (samples as rows)
meth_t_reduced <- t(meth_reduced)

# Check size
dim(meth_t_reduced)  # Should be: N samples × 1000 CpG sites

# Define groups based on your sample 
groups <- factor(c(rep("TC", 3), rep("EPP", 3)))

```


```{r}
meth
# 1. Prepare data
meth_matrix_clean <- na.omit(meth_t_reduced)
meth_matrix_clean
# Function to check variance within groups (LDA can't use CpG with variance = 0)
check_variance <- function(x, groups) {
  sapply(1:ncol(x), function(i) {
    # Check variance within each group
    group_vars <- tapply(x[, i], groups, var, na.rm = TRUE)
    # Return TRUE if any group has zero variance
    any(group_vars == 0 | is.na(group_vars))
  })
}

# Identify problematic variables
const_vars <- check_variance(meth_matrix_clean, groups) #can take time
const_vars
meth_matrix_clean
# Remove them
meth_filtered <- meth_matrix_clean[, !const_vars]
meth_filtered
cat("Removed", sum(const_vars), "constant variables\n")
cat("Remaining variables:", ncol(meth_filtered), "\n")


# 2. Run LDA
lda_result <- lda(meth_filtered, grouping = groups)
predictions <- predict(lda_result)
predictions

# 3. Visualize
plot(predictions$x, 
     col = as.numeric(groups)+1,
     pch = 19, cex = 2,
     xlab = "LD1",
     main = "Linear Discriminant Analysis")
legend("topright", legend = levels(groups), col = 2:3, pch = 19)




# 4. Evaluate classification performance 

# Confusion matrix
confusion <- table(Predicted = predictions$class, Actual = groups)
print(confusion)

# Calculate accuracy
accuracy <- sum(diag(confusion)) / sum(confusion) * 100
cat("Classification accuracy:", round(accuracy, 1), "%\n")

# Posterior probabilities (confidence of classification)
print(predictions$posterior)

# Visualize posterior probabilities
barplot(t(predictions$posterior), 
        beside = TRUE,
        col = c("red", "blue"),
        legend = levels(groups),
        main = "Classification probabilities",
        xlab = "Sample",
        ylab = "Posterior probability")


# Identify most discriminative CpGs

# Extract LDA coefficients (loadings)
loadings <- lda_result$scaling[, 1]  # First discriminant

# Sort by absolute value (most important)
top_indices <- order(abs(loadings), decreasing = TRUE)[1:20]

# Create dataframe
top_cpgs <- data.frame(
  Rank = 1:20,
  CpG_index = top_indices,
  LD1_coefficient = loadings[top_indices],
  abs_coefficient = abs(loadings[top_indices])
)

print(top_cpgs)

# Visualize top discriminative CpGs
par(mar = c(5, 10, 4, 2))
barplot(top_cpgs$LD1_coefficient[20:1],
        horiz = TRUE,
        names.arg = top_cpgs$CpG_index[20:1],
        col = ifelse(top_cpgs$LD1_coefficient[20:1] > 0, "red", "blue"),
        main = "Top 20 discriminative CpGs",
        xlab = "LDA coefficient",
        las = 1)
abline(v = 0, lty = 2)
legend("bottomright", 
       legend = c("Enriched in Treatment", "Enriched in Control"),
       fill = c("red", "blue"))


```


## Extracting regions of interest

```{r}

getSampleID(meth)

#Reorganize if necessary
new.meth <- reorganize(meth,sample.ids=c("TC","EPP"),treatment=c(1,0))

```

Calculate the different methylation (it can take few minutes)
the most efficient is to use Logistic regression with correction for overdispersion
Length as covariate:
Length of fish 2: 4.036 ; 3:  2.187 ; 4: 2.288 ; 69: 3.322 ; 71: 3.552 ; 73: 2.841

```{r}

x
x
x
x
x
x
x
x

saveRDS(dm.lr, file="RAW_data_Florida_Belize/RDS/DMClr.RDS")
dm.lr <- readRDS(file = "RAW_data_Florida_Belize/RDS/DMClr.RDS" )

```

Alternatively, we can use a beta binomial distribution

```{r}

?calculateDiffMethDSS

dm.dss=calculateDiffMethDSS(meth, adjust = "SLIM")
dm.dss

```

Determine the cutoffs

```{r}

# get differentially methylated bases/regions with specific cutoffs of difference 10, and qvalue 0.01. Name it alldiff
x
x
x

# get hyper-methylated
x
x

# get hypo-methylated
x
x

#export the results in CSV file to visualize in SeqMonq
#write.csv2(all.diff, file = "RAW_data_Florida_Belize/CSV/DMR_EPP_TC_all.csv")
#write.csv2(dm.lr, file = "RAW_data_Florida_Belize/CSV/analyzed_regions_EPP_TC.csv")

#what is the % of CpG that are differentially methylated ?
```





## We can do the analysis on regions and not CpGs
!!! long processing time

```{r}

myobj_lowCov <- methRead(file.list,
           sample.id=list("TC1","TC2","TC3", "EPP1", "EPP2", "EPP3"),
           assembly="ASM164957v2",
           treatment=c(1,1,1,0,0,0),
           context="CpG",
           mincov = 3
           )

saveRDS(myobj_lowCov, file="RAW_data_Florida_Belize/RDS/myobj_lowCov.RDS")
myobj_lowCov <- readRDS("RAW_data_Florida_Belize/RDS/myobj_lowCov.RDS")

?tileMethylCounts

tiles <-  tileMethylCounts(myobj_lowCov,win.size=300,step.size=300,cov.bases = 3)
head(tiles[[1]])
?tileMethylCounts
tiles[[1]]
head(tiles[[1]])
length(tiles)
class(tiles)

saveRDS(tiles, file="RAW_data_Florida_Belize/RDS/tiles1.RDS")
tiles <- readRDS("RAW_data_Florida_Belize/RDS/tiles1.RDS")

#unite
alltiles <- methylKit::unite(tiles, destrand=FALSE, min.per.group = NULL)
alltiles

```


```{r}

pmat=percMethylation(alltiles) 
head(pmat)
summary(pmat)

#calculate coefficient of variation for each CpG in TC and EPP
CV <- function(x){sd(x)/mean(x)*100}

tilesTC <- apply(pmat[,1:3], MARGIN=1,FUN = CV)
summary(tilesTC)
head(tilesTC)
tilesEPP <- apply(pmat[,4:6], MARGIN=1,FUN = CV)
summary(tilesEPP)
CValltiles <- apply(pmat[,1:6], MARGIN=1,FUN = CV)
summary(CValltiles)

hist(CValltiles)

```


```{r}
c <- readRDS("tiles.diff.RDS")
c

dm.lrtiles=calculateDiffMeth(alltiles,overdispersion = "MN",test ="Chisq", covariate=NULL, adjust = "SLIM")
dm.lr

tiles.diff=getMethylDiff(dm.lrtiles,difference=10,qvalue=0.01,type="all")
tiles.diff

saveRDS(tiles.diff, file="RAW_data_Florida_Belize/RDS/tiles.diff.RDS")


```


# 4° Annotation

The annotation is made in SeqMonk. Here we upload the .CSV file generated by SeqMonk.

```{r}
DMC_ID_all<-read.table(file = "RAW_data_Florida_Belize/results/Seqmonk_table_DMC_all.csv", header = T, sep=",", dec = ",", check.names=F)

#colnames(all.diff)[colnames(all.diff) == "start"] <- "Start"

selected_meth_alldata <- getData(dm.lr)[, c("chr", "start", "end")]

DMC_ID_all$start <- as.integer(DMC_ID_all$start)

selected_meth_alldata$start <- as.integer(selected_meth_alldata$start)

merged <- dplyr::inner_join(selected_meth_alldata, DMC_ID_all, by = "start")

nrow(merged)
str(merged)

merged


```


```{r}

GTF <- rtracklayer::import('Sequences/genomic.gtf')
length(GTF)  
class(GTF)
head(GTF)
unique(GTF$type)
unique(GTF$gene_id)

GTFsplit=as(split(GTF, GTF$type), "GRangesList")
length(GTFsplit)
GTFsplit
GTFsplit[[6]]

all.diffG <- as(all.diff, "GRanges")

annotateWithFeatures(all.diffG,GTFsplit)

```
! GenomicTools is not supported in CRAN anymore


After the analysis in SeqMonk, create a final table.

```{r}
# 1. Load your files

# SeqMonk annotation file
seqmonk_annot <- read.table("Raw_data_Florida_Belize/results/Seqmonk_table_DMC_all_2026.txt", 
                            header = TRUE, 
                            sep = "\t", 
                            stringsAsFactors = FALSE)
seqmonk_annot

# Original methylKit results (with qvalue and meth.diff)
readLines("RAW_data_Florida_Belize/results/DMC_EPP_TC_all.csv", n = 5)

methylkit_results <- read.csv2("RAW_data_Florida_Belize/results/DMC_EPP_TC_all.csv", 
                               stringsAsFactors = FALSE)

# 2. Check the column names
head(seqmonk_annot)
head(methylkit_results)

seqmonk_annot <- seqmonk_annot %>%
  rename(chr = Chromosome,
         start = Start)


# 3. Merge by genomic coordinates
# Assuming both have: chr, start, end (or similar)
combined <- methylkit_results %>%
  left_join(seqmonk_annot, 
            by = c("chr", "start"))
combined

# 4. Select and reorder columns you want
final_table <- combined %>%
  select(chr, start, 
         meth.diff, qvalue,  # from methylKit
         Feature, Distance, Feature.Orientation, Feature.Strand)  # from SeqMonk - adjust name

final_table_sorted <- final_table %>%
  arrange(desc(abs(meth.diff)))

final_table_sorted

# 5. Save the combined table
write.csv(final_table_sorted, "cpg_annotated_with_stats.csv", row.names = FALSE)

#6 Sort a list of unique genes
genes_uniques <- final_table_sorted %>%
  filter(!is.na(Feature) & Feature != "") %>%
  pull(Feature) %>%
  unique()

genes_uniques

```


