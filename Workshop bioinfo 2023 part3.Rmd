---
title: "DNA methylation workflow - workshop 2025 part3"
author: "Frederic Silvestre"
date: "20/02/2025"
output: html_document
---

This part3 of the DNA methylation workflow aims to work on real RAW data obtained after RRBS bisulfite sequencing using an Ilumina sequencer. The data consists in 6 libraries of mangrove rivulus brain sampled in 2019 in two wild population: EPP (Emerson Point Preserve in Florida ; TC (Twin Cayes in Belize).

ID of fish from Twin Caye: Brain 2, 3, 4
ID of fish from EPP: ID Brain 69, 71, 73

The RAW files are in the file "fastq" with the name "BrainX.fastq.gz"

For the scientific background, see the presentation.



# 0° Preparation of the working environment


## Install R v4.4 and update RStudio


https://www.listendata.com/2015/08/how-to-update-r-software.html 

Go to the CRAN website.
For Windows Users - https://cran.r-project.org/bin/windows/base/.
For Mac Users - https://cran.r-project.org/bin/macosx/
Download the latest R installer.
Run the installer, and it will guide you through the installation process.
After updating R, open RStudio. Close RStudio if it is already opened and open it again.
RStudio will automatically detect the updated R version. Run this command R.version.string to check the R version RStudio is using.

The R packages are located in (for mac users) : computername/Library/Frameworks/R.framework/Versions/X.XX/Resources/library

Copy all the old R version packages to the new version. Update the packages.

Install the last version of R studio:
https://posit.co/download/rstudio-desktop/ 

```{r eval=F}

R.version.string
#you can also use the command line R --version

options(repos = c(CRAN = "https://cloud.r-project.org/")) #seta  CRAN mirror (repository URL) to check for package updates

update.packages(ask=F)

packageStatus()

sessionInfo()

```


## General setup of RMarkdown chunks and common shortcuts (for MacOS)


```{r eval=F}
if(!requireNamespace("knitr", quietly=TRUE)){
        install.packages("knitr")
library(knitr)}

if(!requireNamespace("rmarkdown", quietly=TRUE)){
        install.packages("rmarkdown")
library(rmarkdown)}

if(!requireNamespace("tinytex", quietly=TRUE)) { #this package will permit to knit into a pdf file
library(tinytex) }
tinytex::install_tinytex()

```

```{r eval=T}
knitr::opts_chunk$set(eval=F, results="markup", echo = T, warning=F, error=T)
```

Change the general options in each chunk: eval=T (run the chunk); results=markup (show the results) or hide ; echo=T (show the code) ; include=T (include the chunk)    
Option/CTL I to create a chunk  
Shift/option ( to [ 
Option ( to { 
| shift/option L  
~ option n  
shift/option/command G > go to line xxx
double space to change the paragraph  


## Set working directory 


```{r}
setwd("/Users/fsilvest/Documents/bioinformatic_workshop/") # adapt to your computer
getwd()

ls()
rm(list = ls())

tempdir() #where to save temporary data from R
list.files(tempdir())
unlink(tempdir(), recursive = TRUE) #often, we must restart Rstudio

dev.off() #to reset the graph device options

```


## Install Bioconductor 3.20 and requested packages


Bioconductor: https://www.bioconductor.org/
https://www.bioconductor.org/install/ 

search for available packages: https://www.bioconductor.org/packages/release/BiocViews.html#___Software

```{r}
# Check the version of BiocManager on your computer
BiocManager::version()

if (!require("BiocManager", quietly = TRUE)) {
    install.packages("BiocManager")
BiocManager::install(version = "3.20")
library(BiocManager)}

#To check the number of packages available in Bioconductor
avail <- BiocManager::available()
length(avail)

#update your packages
BiocManager::install()
```


```{r}
#if (!require("stringi", quietly = TRUE)) {
#      install.packages("stringi",type="mac.binary") 
#      library(stringi)}

#mac.binary > if an error message appears (aucun package nommé ‘stringi’ n'est trouvé)

bioc_packages <- c("GenomicRanges", "GenomeInfoDb", "IRanges", "Biostrings", "BSgenome", "AnnotationHub", "GenomicFeatures", "SGSeq", "qvalue", "pwalign", "methylKit", "ShortRead","genomation", "remotes", "txdbmaker", "fastqcr", "Rqc", "QuasR")  

cran_packages <- c("factoextra", "gridExtra", "ggplot2", "psych", "diptest")


for (pkg in bioc_packages) {
    if (!requireNamespace(pkg, quietly = TRUE)) {
        BiocManager::install(pkg, ask = FALSE)
    }
    library(pkg, character.only = TRUE)
}


for (pkg in cran_packages) {
    if (!requireNamespace(pkg, quietly = TRUE)) {
        install.packages(pkg, dependencies = TRUE)
    }
    library(pkg, character.only = TRUE)
}

```


## To obtain help


```{r}

?mean
help.start()
help(package = "GenomicRanges")
vignette()
vignette("ExpressionSetIntroduction")
browseVignettes("GenomicRanges")

```


## To save and load R objects


```{r}

saveRDS(tiles, file="RDS/tiles1.RDS")
b <- readRDS("RDS/tiles1.RDS")

```



# 1° Quality check

Working with FastQ files
Usually, we work with FastQC app or multi FASTQC (https://www.bioinformatics.babraham.ac.uk/projects/fastqc/).


```{r}
#to verify if the image exists and the full pathway
file.exists("images/Phred.png")
normalizePath("images/Phred.png")

```

![Phred values](/Users/fsilvest/Documents/bioinformatic_workshop/images/Phred.png)

![FASTQ sequence](/Users/fsilvest/Documents/bioinformatic_workshop/images/Phred2.png)

Example of quality check option using Rqc package.

In the package Rqc, we must load fastq.gz files. If we start from fasta.gz, we can convert it using the lines below from the package ShortRead.

```{r}
# Read fasta file
fasta_data <- readFasta("input.fasta.gz")

# Convert and write to FASTQ
writeFastq(fasta_data, "output.fastq.gz", compress=TRUE)
```



```{r}

folder <- system.file(package="ShortRead", "extdata/E-MTAB-1147") #example dataset

?rqc
vignette("Rqc")

qcRes <- rqc(path=folder, pattern=".fastq.gz", openBrowser=F)
perFileInformation(qcRes)

saveRDS(qcRes, file="RAW_data_Florida_Belize/RDS/qcRes.RDS")
qcRes <- readRDS("RAW_data_Florida_Belize/RDS/qcRes.RDS")
qcRes

rqcReadQualityBoxPlot(qcRes)
rqcReadQualityPlot(qcRes)
rqcCycleAverageQualityPlot(qcRes)
rqcReadFrequencyPlot(qcRes)
rqcCycleQualityPlot(qcRes)
rqcCycleAverageQualityPcaPlot(qcRes)
rqcCycleBaseCallsLinePlot(qcRes)

# we can run and save the analysis in a html report

files <- list.files(folder, "fastq.gz", full.names=TRUE)
qa <- rqcQA(files, workers=1)
qa

saveRDS(qa, file="RAW_data_Florida_Belize/RDS/qa.RDS")
qa <- readRDS("RAW_data_Florida_Belize/RDS/qa.RDS")

reportFile <- rqcReport(qa)
saveRDS(reportFile, file="RAW_data_Florida_Belize/RDS/reportFile.RDS")
readRDS("RAW_data_Florida_Belize/RDS/reportFile.RDS")
browseURL(reportFile)
system(paste("open", reportFile))  # For macOS


```

**How to interpret the ReadFrequency graph ?**

Most Reads Appear Once

In a typical, high-complexity library, you expect a large proportion of reads to be unique (frequency = 1).
The bar or point at frequency = 1 is often the highest on the plot.
Reads with Higher Frequencies

If you see a significant spike in reads that appear 10, 50, or 100 times (etc.), it suggests duplication.
Moderate duplication (a small tail at higher frequencies) can be normal, especially in targeted sequencing (amplicon-based) or if your sample is highly expressed in certain transcripts.
Excessive Duplication

A large portion of reads with very high frequencies can indicate technical artifacts (PCR over-amplification, adapter contamination).
In severe cases, you might need to remove duplicates or improve library prep methods.


**Analyse the sequencing quality of the rivulus samples and compare the results to the example files above.**

```{r}

folderkm <- "/Users/fsilvest/Documents/bioinformatic_workshop/RAW_data_Florida_Belize/fastq/" #real dataset
list.files(folderkm)


#*****

```

```{r}

# we can analyse a single sample and work on the sequence

fq <- readFastq("RAW_data_Florida_Belize/fastq/Brain2.fastq.gz") #long time
fq

saveRDS(fq, file="RAW_data_Florida_Belize/RDS/fqBrain2.RDS")
fq <- readRDS("RAW_data_Florida_Belize/RDS/fqBrain2.RDS")

class(fq)
sequences <- sread(fq)
sequences
id(fq)
qfq <- quality(fq)
qfq
class(qfq)

qPerBase=as(quality(fq[1]), "matrix")
qPerBase
qcount=rowSums(qPerBase<=20)
qcount

```



# 2° Filter and trim the reads

We must trim the reads to increase the quality to have a good alignment. For that, we usually use TRIM GALORE (which is using CUTADAPT)
	- remove adapters
	- remove low quality nucleotides (< 20)
	- remove the end-repaired C at the extremity (--rrbs)
	
To help installing Trim Galore ! : https://github.com/FelixKrueger/TrimGalore 
	
Alternatively, we can use QuasR but less good for RRBS.

```{r}

vignette("QuasR")

fastqFiles <- system.file(package="ShortRead",
                          "extdata/E-MTAB-1147",
                          c("ERR127302_1_subset.fastq.gz",
                            "ERR127302_2_subset.fastq.gz"))
outfiles <- paste(tempfile(pattern=c("processed_1_",
                                     "processed_2_")),".fastq", sep="")

?preprocessReads

preprocessReads(fastqFiles, outfiles,
                nBases=1,
                truncateEndBases=3,
                Lpattern="ACCCGGGA",
                minLength=40)

fastqFile <- system.file(package="ShortRead",
                          "extdata/E-MTAB-1147",
                          "ERR127302_1_subset.fastq.gz")

fq <- readFastq(fastqFile)
qPerBase=as(quality(fq), "matrix")
qcount=rowSums(qPerBase<=20)
fq[qcount==0]
writeFastq(fq[qcount==0],
           paste(fastqFile, "Qfiltered", sep="_")) 

#with real samples (too long)
preprocessReads(filename = "RAW_data_Florida_Belize/fastq/Brain2.fastq.gz", outputFilename="RAW_data_Florida_Belize/fastq/Brain2trimQuasR.fastq.gz", truncateEndBases= 2, nBases=1, minLength=40, Lpattern="AGATCGGAAGAG")

qcReskmtrim <- rqc(path="RAW_data_Florida_Belize/fastq_trim", pattern=".fastq.gz", openBrowser=FALSE) #takes time
perFileInformation(qcReskmtrim)

rqcReadQualityBoxPlot(qcReskmtrim)
rqcReadQualityPlot(qcReskmtrim)
rqcCycleAverageQualityPlot(qcReskmtrim)
rqcReadFrequencyPlot(qcReskmtrim)
rqcCycleQualityPlot(qcReskmtrim)
rqcCycleAverageQualityPcaPlot(qcReskmtrim)
rqcCycleBaseCallsLinePlot(qcReskmtrim)

files <- list.files("RAW_data_Florida_Belize/fastq_trim", "fastq.gz", full.names=TRUE)
qakm <- rqcQA(files, workers=1) #takes time
qakm

reportFilekm <- rqcReport(qakm)

browseURL(reportFilekm)

#Illumina univeral adaptor= AGATCGGAAGAG

```

The result of the trimming of Brain2 can be summarized here:

![Trim Brain2](/Users/fsilvest/Documents/bioinformatic_workshop/images/tabletrimBrain2.png)

After trimming and quality control, we can align the sequences to the reference genome. For BiSeq, we use Bismark (which is using Bowtie2): https://www.bioinformatics.babraham.ac.uk/projects/bismark/ 

A reference genome assembly must be first downloaded. For rivulus, the last genome assembly (RefSeq assembly accession: GCF_001649575.2 ) can be found here: https://www.ncbi.nlm.nih.gov/data-hub/genome/GCF_001649575.2/

Then the genome must be prepared for RRBS before running Bismark with chosen options.

Example:

Prepare the genome for RRBS if we first use the genome:
/Applications/Bismark-0.22.3/bismark_genome_preparation --path_to_aligner /Applications/bowtie/bin/ --verbose ~/bioinformatic_workshop/RAW_data_Florida_Belize/Sequences/genomeDovetail/

-Run Bismark:
/Applications/Bismark-0.22.3/bismark --genome ~/bioinformatic_workshop/RAW_data_Florida_Belize/Sequences/genomeDovetail/ --score_min L,0,-0.6 --output_dir ~/bioinformatic_workshop/RAW_data_Florida_Belize/Bismark_output ~/bioinformatic_workshop/RAW_data_Florida_Belize/TrimGalore_output/Brain2_trimmed_simple_nondir.fq.gz

The output are sam.gz files that must first be uncompressed.
Bismark writes a report in .txt where we can find many infos such as the average % methylation.

We must first reorganize the  files after Bismark with the samtools package from the terminal.

Now we read a file from Bismark with the format .SAM
SAM files must be sorted by chromosome and read position columns, using ‘sort’ command in unix-like machines will accomplish such a sort easily. BAM files should be sorted and indexed. This could be achieved with samtools (http://www.htslib.org/doc/samtools.html).
Follow samtools tutorial: http://quinlanlab.org/tutorials/samtools/samtools.html#:~:text=samtools%20%E2%80%9Csort%E2%80%9D&text=In%20other%20words%2C%20the%20BAM,in%20the%20input%20FASTQ%20files.&text=Doing%20anything%20meaningful%20such%20as,occur%20in%20%E2%80%9Cgenome%20order%E2%80%9D.
List of terminal commands: https://www.makeuseof.com/tag/mac-terminal-commands-cheat-sheet/

cd ~
mkdir methylome
cd ~/methylome
git clone https://github.com/samtools/htslib
git clone https://github.com/samtools/samtools
cd samtools
make
!!!! to use a command while you are in the good directory: ./samtools
cd .. #to come back in methylome
./samtools/samtools view CTL1.bam| head

When you align FASTQ files with all current sequence aligners, the alignments produced are in random order with respect to their position in the reference genome. In other words, the BAM file is in the order that the sequences occurred in the input FASTQ files.

./samtools/samtools sort CTL1.bam -o CTL1.sorted.bam



# 3° Working in methylKit

## Importing the data in methylKit

Once the files are in .BAM format after Samtools, we can import them in methylKit package in R using processBismarkAln function.

We can now do it at once for several files (it takes 6-7min per file)
It's an object methylRawList of 6

The file has been saved in the txt file to save time: 2_CpG.txt, etc


```{r}

file.list <- list( "Brain2.sorted.bam", "Brain3.sorted.bam", "Brain4.sorted.bam","Brain69.sorted.bam", "Brain71.sorted.bam", "Brain73.sorted.bam")

#it takes a lot of time
myobj <- processBismarkAln(file.list,
           sample.id=list("TC1","TC2","TC3", "EPP1", "EPP2", "EPP3"),
           assembly="ASM164957v2",
           treatment=c(1,1,1,0,0,0),
           read.context="CpG",
           save.folder = getwd(),
           mincov = 10
           )

#characterize myobj
length(myobj)
class(myobj)
head(myobj)


file.list <- list("/RAW_data_Florida_Belize/txt/2_CpG.txt", "/RAW_data_Florida_Belize/txt/3_CpG.txt", "/RAW_data_Florida_Belize/txt/4_CpG.txt", "/RAW_data_Florida_Belize/txt/69_CpG.txt", "/RAW_data_Florida_Belize/txt/71_CpG.txt", "/RAW_data_Florida_Belize/txt/73_CpG.txt")

myobj <- methRead(file.list,
           sample.id=list("TC1","TC2","TC3", "EPP1", "EPP2", "EPP3"),
           assembly="ASM164957v2",
           treatment=c(1,1,1,0,0,0),
           context="CpG",
           mincov = 10
           )

saveRDS(myobj, file="/Users/fsilvestre/bioinformatic_workshop/RAW_data_Florida_Belize/RDS/TC-EPP.RDS")
myobj <- readRDS("RAW_data_Florida_Belize/RDS/TC-EPP.RDS")

myobj

#how many CpG are there ?

```


## Analyse the CpG on each file and filter to get rid of the low quality

```{r}
#analyse the 6 graphs and extract the median values for each sample.

getMethylationStats(myobj[[1]],plot=TRUE,both.strands=F)

#****

```


```{r}

#Get the 6 graphs for the coverage values

#****

```


```{r}

# filter your object with lo.count=10 and hi.perc=99.9


#we can be more stringent and take a min coverage of 20


#what are the differences between filtered by 10 or 20 ?

```



## Unite the different files in the same object

We can set a minimum number of samples covered min.per.group (1L, 2L, 3L)

```{r}

meth <- methylKit::unite(filtered.myobj, destrand=T, min.per.group = NULL)
meth

meth2L <- methylKit::unite(filtered.myobj, destrand=T, min.per.group = 2L)
meth2L

meth20 <- methylKit::unite(filtered.myobj20, destrand=T, min.per.group = NULL)
meth20

#compare the number of CpG analyzed with different parameters of min.per.group and coverage. What is the best option to chose ?

```


## Explore the variability of each CpG

```{r}

# What are the mean CV for TC, EPP and all together ?

```



## PCA and clustering 

Only on a matrix with no NA (CpG in all samples)

**Make a clustering and a PCA analysis**



## Extracting regions of interest

```{r}

getSampleID(meth)

#Reorganize if necessary
new.meth <- reorganize(meth,sample.ids=c("TC","EPP"),treatment=c(1,0))

```

Calculate the different methylation (it can take few minutes)
the most efficient is to use Logistic regression with correction for overdispersion
Length as covariate:
Length of fish 2: 4.036 ; 3:  2.187 ; 4: 2.288 ; 69: 3.322 ; 71: 3.552 ; 73: 2.841

```{r}

lengthcov <- c(4.036, 2.187,2.288, 3.322, 3.552, 2.841)
sampleIDs <- c(2,3,4,69,71,73)
covar <- data.frame(sampleID = sampleIDs, length = lengthcov) 
covar

dm.lr <- calculateDiffMeth(meth, overdispersion = "MN",test ="Chisq", covariate=covar, adjust = "SLIM") #takes long time

dm.lr

saveRDS(dm.lr, file="RAW_data_Florida_Belize/RDS/DMClr.RDS")
dm.lr <- readRDS(file = "RAW_data_Florida_Belize/RDS/DMClr.RDS" )

```

Alternatively, we can use a beta binomial distribution

```{r}

?calculateDiffMethDSS

dm.dss=calculateDiffMethDSS(meth, adjust = "SLIM")
dm.dss

```

Determine the cutoffs

**Make a selection of CpG based on your chosen parameters and save it in a csv file.**

```{r}


#export the results in CSV file to visualize in SeqMonq
write.csv2(all.diff, file = "RAW_data_Florida_Belize/CSV/DMR_EPP_TC_all.csv")

#what is the % of CpG that are differentially methylated ?
```



## We can do the analysis on regions and not CpGs
!!! long processing time

```{r}

myobj_lowCov <- methRead(file.list,
           sample.id=list("TC1","TC2","TC3", "EPP1", "EPP2", "EPP3"),
           assembly="ASM164957v2",
           treatment=c(1,1,1,0,0,0),
           context="CpG",
           mincov = 3
           )

saveRDS(myobj_lowCov, file="RAW_data_Florida_Belize/RDS/myobj_lowCov.RDS")
myobj_lowCov <- readRDS("RAW_data_Florida_Belize/RDS/myobj_lowCov.RDS")

?tileMethylCounts

tiles <-  tileMethylCounts(myobj_lowCov,win.size=300,step.size=300,cov.bases = 3)
head(tiles[[1]])
?tileMethylCounts
tiles[[1]]
head(tiles[[1]])
length(tiles)
class(tiles)

saveRDS(tiles, file="RAW_data_Florida_Belize/RDS/tiles1.RDS")
tiles <- readRDS("RAW_data_Florida_Belize/RDS/tiles1.RDS")

#unite
alltiles <- methylKit::unite(tiles, destrand=FALSE, min.per.group = NULL)
alltiles

```


```{r}

pmat=percMethylation(alltiles) 
head(pmat)
summary(pmat)

#calculate coefficient of variation for each CpG in TC and EPP
CV <- function(x){sd(x)/mean(x)*100}

tilesTC <- apply(pmat[,1:3], MARGIN=1,FUN = CV)
summary(tilesTC)
head(tilesTC)
tilesEPP <- apply(pmat[,4:6], MARGIN=1,FUN = CV)
summary(tilesEPP)
CValltiles <- apply(pmat[,1:6], MARGIN=1,FUN = CV)
summary(CValltiles)

hist(CValltiles)

```


```{r}
c <- readRDS("tiles.diff.RDS")
c

dm.lrtiles=calculateDiffMeth(alltiles,overdispersion = "MN",test ="Chisq", covariate=NULL, adjust = "SLIM")
dm.lr

tiles.diff=getMethylDiff(dm.lrtiles,difference=10,qvalue=0.01,type="all")
tiles.diff

saveRDS(tiles.diff, file="RAW_data_Florida_Belize/RDS/tiles.diff.RDS")


```


# 4° Annotation

**cfr SeqMonk

