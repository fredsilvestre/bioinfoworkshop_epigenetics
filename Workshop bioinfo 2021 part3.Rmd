---
title: "DNA methylation workflow - workshop 2023 part3"
author: "Frederic Silvestre"
date: "17/1/2023"
output: html_document
---

This part3 of the DNA methylation workflow aims to work on real RAW data obtained after RRBS bisulfite sequencing using an Ilumina sequencer. The data consists in 6 libraries of mangrove rivulus brain sampled in 2019 in two wild population: EPP (Emerson Point Preserve in Florida ; TC (Twin Cayes in Belize).

ID of fish from Twin Caye: Brain2, 3, 4
ID of fish from EPP: ID Brain69, 71, 73

The RAW files are in the file "fastq" with the name "Brain2.fastq.gz"

For the scientific background, see the presentation.



# 0° Preparation of the working environment

## General setup of RMarkdown chunks and common shortcuts (for MacOS)

```{r setup}
if(!requireNamespace("knitr", quietly=TRUE))
        install.packages("knitr")
library(knitr)
if(!requireNamespace("rmarkdown", quietly=TRUE))
        install.packages("rmarkdown")
library(rmarkdown)

knitr::opts_chunk$set(eval=F, results="hide", echo = TRUE, include=TRUE, warning=TRUE, error=TRUE)
```

Change the general options in each chunk: eval=T (run the chunk); results=markup (show the results) or hide ; echo=T (show the code) ; include=T (include the chunk)    
Option/Command I to create a chunk  
Shift/option ( to [  
Option ( to {  
| shift/option L  
~ option n  
double space to change the paragraph  
to open /var folder > command + shift + G (write /var)  

## Set working directory 

```{r eval=T}
getwd()
setwd("*****") # adapt to your computer
ls()
rm(list = ls())
tempdir() #where to save all the data from R
dev.off() #to reset the graph device options
sessionInfo()

```

## Install R v4.2 and update RStudio


## Install Bioconductor 3.16 and requested packages

Bioconductor: https://www.bioconductor.org/
search for available packages: https://www.bioconductor.org/packages/release/BiocViews.html#___Software

```{r}
# Check the version of BiocManager on your computer
BiocManager::version()

if(!requireNamespace("BiocManager", quietly=TRUE))
        install.packages("BiocManager")
BiocManager::install(version="3.16")

library(BiocManager)

#To check the number of packages available in Bioconductor
avail <- BiocManager::available()
length(avail)

#update your packages
BiocManager::install()

install.packages("stringi",type="mac.binary") #if an error message appears (aucun package nommé ‘stringi’ n'est trouvé)
library(stringi)

if(!requireNamespace("pacman", quietly=TRUE)) #the package pacman allows to install and load several packages from Cran at once if they're not installed.
        install.packages("pacman")
library(pacman)

BiocManager::install(c("Rqc", "methylKit", "ShortRead", "QuasR"))
pacman::p_load(Rqc, methylKit, ShortRead, QuasR, remotes, factoextra)

BiocManager::install("methylKit", force=T) # if it does not work

```

## To obtain help

```{r}

?mean
help.start()
help(package = "methylKit")
vignette("methylKit")
browseVignettes("methylKit")

```

## To save and load R objects

```{r}

saveRDS(tiles, file="tiles1.RDS")
b <- readRDS("tiles1.RDS")

```



# 1° Quality check

Working with FastQ files
Usually, we work with FastQC app or multi FASTQC (https://www.bioinformatics.babraham.ac.uk/projects/fastqc/).

![Phred values](images/Phred.png)

![FASTQ sequence](images/Phred2.png)


```{r}

folder <- system.file(package="ShortRead", "extdata/E-MTAB-1147") #example dataset

folder <- "/Users/fsilvestre/bioinformatic_workshop/RAW_data_Florida_Belize/fastq/" #real dataset

?rqc
vignette("Rqc")

qcRes <- rqc(path=folder, pattern=".fastq.gz", openBrowser=FALSE)
perFileInformation(qcRes)

saveRDS(qcRes, file="RAW_data_Florida_Belize/RDS/qcRes.RDS")
qcRes <- readRDS("RAW_data_Florida_Belize/RDS/qcRes.RDS")
qcRes

rqcReadQualityBoxPlot(qcRes)
rqcReadQualityPlot(qcRes)
rqcCycleAverageQualityPlot(qcRes)
rqcReadFrequencyPlot(qcRes)
rqcCycleQualityPlot(qcRes)
rqcCycleAverageQualityPcaPlot(qcRes)
rqcCycleBaseCallsLinePlot(qcRes)

#we can save the analysis in a html report

files <- list.files(folder, "fastq.gz", full.names=TRUE)
qa <- rqcQA(files, workers=1)

saveRDS(qa, file="RAW_data_Florida_Belize/RDS/qa.RDS")
qa <- readRDS("RAW_data_Florida_Belize/RDS/qa.RDS")

reportFile <- rqcReport(qa)
saveRDS(reportFile, file="RAW_data_Florida_Belize/RDS/reportFile.RDS")
readRDS("RAW_data_Florida_Belize/RDS/reportFile.RDS")
browseURL(reportFile)


# we can analyse a single sample and work on the sequence
fq <- readFastq("RAW_data_Florida_Belize/fastq/Brain2.fastq.gz") #long time
fq

saveRDS(fq, file="RAW_data_Florida_Belize/RDS/fqBrain2.RDS")
fq <- readRDS("RAW_data_Florida_Belize/RDS/fqBrain2.RDS")

class(fq)
sequences <- sread(fq)
sequences
id(fq)
qfq <- quality(fq)
qfq
class(qfq)

qPerBase=as(quality(fq[1]), "matrix")
qPerBase
qcount=rowSums(qPerBase<=20)
qcount
```


We can use the package fastqcr to aggregate several FASTQC reports in .zip
http://www.sthda.com/english/wiki/fastqcr-an-r-package-facilitating-quality-controls-of-sequencing-data-for-large-numbers-of-samples 

```{r}
install.packages("fastqcr")
library("fastqcr")
```



# 2° Filter et trim the reads

We must trim the reads to increase the quality to have a good alignment. For that, we usually use TRIM GALORE (which is using CUTADAPT)
	- remove adapters
	- remove low quality nucleotides (< 20)
	- remove the end-repaired C at the extremity (--rrbs)
	
Alternatively, we can use QuasR but less good for RRBS.

```{r}

vignette("QuasR")

fastqFiles <- system.file(package="ShortRead",
                          "extdata/E-MTAB-1147",
                          c("ERR127302_1_subset.fastq.gz",
                            "ERR127302_2_subset.fastq.gz"))
outfiles <- paste(tempfile(pattern=c("processed_1_",
                                     "processed_2_")),".fastq", sep="")
preprocessReads(fastqFiles, outfiles,
                nBases=1,
                truncateEndBases=3,
                Lpattern="ACCCGGGA",
                minLength=40)

fastqFile <- system.file(package="ShortRead",
                          "extdata/E-MTAB-1147",
                          "ERR127302_1_subset.fastq.gz")
fq <- readFastq(fastqFile)
qPerBase=as(quality(fq), "matrix")
qcount=rowSums(qPerBase<=20)
fq[qcount==0]
writeFastq(fq[qcount==0],
           paste(fastqFile, "Qfiltered", sep="_")) #réécrire un nouveau fichier fastq

#with real samples (too long)
preprocessReads(filename = "RAW_data_Florida_Belize/fastq/Brain2.fastq.gz", outputFilename="RAW_data_Florida_Belize/fastq/Brain2trimQuasR.fastq.gz", truncateEndBases= 2, nBases=1, minLength=40, Lpattern="AGATCGGAAGAG")

#Illumina univeral adaptor= AGATCGGAAGAG

```

The result of the trimming of Brain2 can be summarized here:

![Trim Brain2](images/tabletrimBrain2.png)
After trimming and quality control, we can aligned the sequences to the reference genome. For BiSeq, we use Bismark (which is using Bowtie2): https://www.bioinformatics.babraham.ac.uk/projects/bismark/ 

A reference genome assembly must be first downloaded. For rivulus, the last genome assembly (RefSeq assembly accession: GCF_001649575.2 ) can be found here: https://www.ncbi.nlm.nih.gov/data-hub/genome/GCF_001649575.2/

Then the genome must be prepared for RRBS before running Bismark with chosen options.

Example:

Prepare the genome for RRBS if we first use the genome:
/Applications/Bismark-0.22.3/bismark_genome_preparation --path_to_aligner /Applications/bowtie/bin/ --verbose ~/bioinformatic_workshop/RAW_data_Florida_Belize/Sequences/genomeDovetail/

-Run Bismark:
/Applications/Bismark-0.22.3/bismark --genome ~/bioinformatic_workshop/RAW_data_Florida_Belize/Sequences/genomeDovetail/ --score_min L,0,-0.6 --output_dir ~/bioinformatic_workshop/RAW_data_Florida_Belize/Bismark_output ~/bioinformatic_workshop/RAW_data_Florida_Belize/TrimGalore_output/Brain2_trimmed_simple_nondir.fq.gz

The output are sam.gz files that must first be uncompressed.
Bismark writes a report in .txt where we can find many infos such as the average % methylation.

We must first reorganize the  files after Bismark with the samtools package from the terminal.

Now we read a file from Bismark with the format .SAM
SAM files must be sorted by chromosome and read position columns, using ‘sort’ command in unix-like machines will accomplish such a sort easily. BAM files should be sorted and indexed. This could be achieved with samtools (http://www.htslib.org/doc/samtools.html).
Follow samtools tutorial: http://quinlanlab.org/tutorials/samtools/samtools.html#:~:text=samtools%20%E2%80%9Csort%E2%80%9D&text=In%20other%20words%2C%20the%20BAM,in%20the%20input%20FASTQ%20files.&text=Doing%20anything%20meaningful%20such%20as,occur%20in%20%E2%80%9Cgenome%20order%E2%80%9D.
List of terminal commands: https://www.makeuseof.com/tag/mac-terminal-commands-cheat-sheet/

cd ~
mkdir methylome
cd ~/methylome
git clone https://github.com/samtools/htslib
git clone https://github.com/samtools/samtools
cd samtools
make
!!!! to use a command while you are in the good directory: ./samtools
cd .. #to come back in methylome
./samtools/samtools view CTL1.bam| head

When you align FASTQ files with all current sequence aligners, the alignments produced are in random order with respect to their position in the reference genome. In other words, the BAM file is in the order that the sequences occurred in the input FASTQ files.

./samtools/samtools sort CTL1.bam -o CTL1.sorted.bam


# 2° Working in methylKit

## Importing the data in methylKit

Once the files are in .BAM format after Samtools, we can import them in methylKit package in R using processBismarkAln function.

We can now do it at once for several files (it takes 6-7min per file)
It's an object methylRawList of 6

The file has been saved in the txt file to save time: 2_CpG.txt, etc


```{r}

vignette("methylKit")

file.list <- list( "Brain2.sorted.bam", "Brain3.sorted.bam", "Brain4.sorted.bam","Brain69.sorted.bam", "Brain71.sorted.bam", "Brain73.sorted.bam")

#it takes a lot of time
myobj <- processBismarkAln(file.list,
           sample.id=list("TC1","TC2","TC3", "EPP1", "EPP2", "EPP3"),
           assembly="ASM164957v2",
           treatment=c(1,1,1,0,0,0),
           read.context="CpG",
           save.folder = getwd(),
           mincov = 10
           )

#characterize myobj
length(myobj)
class(myobj)
head(myobj)


file.list <- list("/RAW_data_Florida_Belize/txt/2_CpG.txt", "/RAW_data_Florida_Belize/txt/3_CpG.txt", "/RAW_data_Florida_Belize/txt/4_CpG.txt", "/RAW_data_Florida_Belize/txt/69_CpG.txt", "/RAW_data_Florida_Belize/txt/71_CpG.txt", "/RAW_data_Florida_Belize/txt/73_CpG.txt")

myobj <- methRead(file.list,
           sample.id=list("TC1","TC2","TC3", "EPP1", "EPP2", "EPP3"),
           assembly="ASM164957v2",
           treatment=c(1,1,1,0,0,0),
           context="CpG",
           mincov = 10
           )

saveRDS(myobj, file="/Users/fsilvestre/bioinformatic_workshop/RAW_data_Florida_Belize/RDS/TC-EPP.RDS")
myobj <- readRDS("RAW_data_Florida_Belize/RDS/TC-EPP.RDS")

myobj

```

Between 1 312 273 and 1 712 975 rows > CpG

## Analyse the CpG on each file and filter to get rid of the low quality

```{r}

?getMethylationStats

par(mfrow = c(2,3))
for(a in 1:6) {getMethylationStats(myobj[[a]], plot=T, strands = F)}
par(mfrow=c(1,1))

getMethylationStats(myobj[[1]],plot=TRUE,both.strands=F)

```

```{r}

par(mfrow = c(2,3))
for(a in 1:6) {getCoverageStats(myobj[[a]], plot=T, strands = F)}
par(mfrow=c(1,1))

getCoverageStats(myobj[[1]],plot=T,both.strands=FALSE)
getCoverageStats(myobj[[6]],plot=F,both.strands=FALSE)

```

```{r}
?filterByCoverage

filtered.myobj <- filterByCoverage(myobj,lo.count=**,lo.perc=**,
                                      hi.count=**,hi.perc=**)

par(mfrow = c(2,3))
for(a in 1:6) {getCoverageStats(filtered.myobj[[a]], plot=T, strands = F)}
par(mfrow=c(1,1))

getCoverageStats(filtered.myobj[[2]],plot=T,both.strands=FALSE)
getCoverageStats(filtered.myobj[[4]],plot=F,both.strands=FALSE)

filtered.myobj

#we can be more stringent and take a min coverage of 20
filtered.myobj20 <- ***

par(mfrow = c(2,3))
for(a in 1:6) {getCoverageStats(filtered.myobj20[[a]], plot=T, strands = F)}
par(mfrow=c(1,1))

```

Between 1 310 958 and 1 711 258 rows > CpG



## Unite the different files in the same object

We can set a minimum number of samples covered min.per.group (1L, 2L, 3L)

```{r}
?methylKit::unite

meth <- methylKit::unite(filtered.myobj, destrand=T, min.per.group = NULL)
meth

meth2L <- methylKit::unite(filtered.myobj, destrand=T, min.per.group = 2L)
meth2L

meth20 <- methylKit::unite(filtered.myobj20, destrand=T, min.per.group = NULL)
meth20

```
There are 691 258 CpG analyzed in the unite object for CpG in all samples.
If we limit to minimum 2 samples, we have 1 077 721 CpG
If we take a min coverage of 20, we have 269 230 CpG only


## See the variability of each CpG and get the percentage methylation Matrix

```{r}

?percMethylation

pm=percMethylation(meth) # get percent methylation matrix ; only on CpG in all samples
head(pm)
summary(pm)

#calculate the coefficient of variation for each CpG in TC and in EPP
CV <- function(x){sd(x)/mean(x)*100}

TC <- apply(pm[,1:3], MARGIN=1,FUN = CV)
head(TC)
summary(TC)
EPP <- apply(pm[,4:6], MARGIN=1,FUN = CV)
summary(EPP)
CVall <- apply(pm[,1:6], MARGIN=1,FUN = CV)
summary(CVall)

hist(CVall)

```
mean CV TC: 34.36
mean CV EPP: 29.78
mean CV all: 44.01


## PCA and clustering 

Only on a matrix with no NA (CpG in all samples)

```{r}

getCorrelation(meth,plot=F)

```

```{r}

clusterSamples(meth, dist="correlation", method="ward", plot=TRUE)

```

```{r}
?PCASamples

pc <- PCASamples(meth,obj.return = T, adj.lim=c(1,1), comp = c(1,2))


# Eigenvalues
eig.val <- get_eigenvalue(pc)
eig.val
fviz_eig(pc)

```


## Extracting regions of interest

```{r}

getSampleID(meth)

#Reorganize if necessary
new.meth <- reorganize(meth,sample.ids=c("TC","EPP"),treatment=c(1,0))

```

Calculate the different methylation (it can take few minutes)
the most efficient is to use Logistic regression with correction for overdispersion
Length as covariate:
Length of fish 2: 4.036 ; 3:  2.187 ; 4: 2.288 ; 69: 3.322 ; 71: 3.552 ; 73: 2.841

```{r}

?calculateDiffMeth

lengthcov <- c(4.036, 2.187,2.288, 3.322, 3.552, 2.841)
sampleIDs <- c(2,3,4,69,71,73)
covar <- data.frame(sampleID = sampleIDs, length = lengthcov) 
covar

dm.lr <- calculateDiffMeth(meth, overdispersion = "MN",test ="Chisq", covariate=covar, adjust = "SLIM")

dm.lr

saveRDS(dm.lr, file="RAW_data_Florida_Belize/RDS/DMClr.RDS")
dm.lr <- readRDS("RAW_data_Florida_Belize/RDS/DMClr.RDS")

```

Alternatively, we can use a beta binomial distribution

```{r}

?calculateDiffMethDSS

dm.dss=calculateDiffMethDSS(meth, adjust = "SLIM")
dm.dss

```

Determine the cutoffs

```{r}

?getMethylDiff

# get differentially methylated bases/regions with specific cutoffs
all.diff=getMethylDiff(dm.lr,difference=10,qvalue=0.01,type="all")
all.diff
summary(all.diff)

# get hyper-methylated
hyper=getMethylDiff(dm.lr,difference=10,qvalue=0.01,type="hyper")
hyper

# get hypo-methylated
hypo=getMethylDiff(dm.lr,difference=10,qvalue=0.01,type="hypo")
hypo

#export the results in CSV file to visualize in SeqMonq
write.csv2(all.diff, file = "RAW_data_Florida_Belize/CSV/DMR_EPP_TC_all.csv")
write.csv2(dm.lr, file = "RAW_data_Florida_Belize/CSV/analyzed_regions_EPP_TC.csv")


```

We found 3545 DMCs > 3545/691258*100 = 0.51% differentially methylated



## We can do the analysis on regions and not CpGs
!!! long processing time

```{r}

myobj_lowCov <- methRead(file.list,
           sample.id=list("TC1","TC2","TC3", "EPP1", "EPP2", "EPP3"),
           assembly="ASM164957v2",
           treatment=c(1,1,1,0,0,0),
           context="CpG",
           mincov = 3
           )

saveRDS(myobj_lowCov, file="RAW_data_Florida_Belize/RDS/myobj_lowCov.RDS")
myobj_lowCov <- readRDS("RAW_data_Florida_Belize/RDS/myobj_lowCov.RDS")

?tileMethylCounts

tiles <-  tileMethylCounts(myobj_lowCov,win.size=300,step.size=300,cov.bases = 3)
head(tiles[[1]])
?tileMethylCounts
tiles[[1]]
head(tiles[[1]])
length(tiles)
class(tiles)

saveRDS(tiles, file="RAW_data_Florida_Belize/RDS/tiles1.RDS")
tiles <- readRDS("RAW_data_Florida_Belize/RDS/tiles1.RDS")

#unite
alltiles <- methylKit::unite(tiles, destrand=FALSE, min.per.group = NULL)
alltiles

```


```{r}

pmat=percMethylation(alltiles) 
head(pmat)
summary(pmat)

#calculate coefficient of variation for each CpG in TC and EPP
CV <- function(x){sd(x)/mean(x)*100}

tilesTC <- apply(pmat[,1:3], MARGIN=1,FUN = CV)
summary(tilesTC)
head(tilesTC)
tilesEPP <- apply(pmat[,4:6], MARGIN=1,FUN = CV)
summary(tilesEPP)
CValltiles <- apply(pmat[,1:6], MARGIN=1,FUN = CV)
summary(CValltiles)

hist(CValltiles)

```


```{r}
c <- readRDS("tiles.diff.RDS")
c

dm.lrtiles=calculateDiffMeth(alltiles,overdispersion = "MN",test ="Chisq", covariate=NULL, adjust = "SLIM")
dm.lr

tiles.diff=getMethylDiff(dm.lrtiles,difference=10,qvalue=0.01,type="all")
tiles.diff

saveRDS(tiles.diff, file="RAW_data_Florida_Belize/RDS/tiles.diff.RDS")


```


# 3° Annotation

```{r}

BiocManager::install(c("genomation", "rtracklayer", "bedr", "GenomicRanges"))

pacman::p_load(genomation, rtracklayer, GenomicTools, bedr, GenomicRanges)

GTF <- rtracklayer::import('RAW_data_Florida_Belize/Sequences/GTF/genomic.gtf')
length(GTF)  
class(GTF)
head(GTF)
unique(GTF$type)
unique(GTF$gene_id)

GTFsplit=as(split(GTF, GTF$type), "GRangesList")
length(GTFsplit)
GTFsplit
GTFsplit[[6]]

all.diffG <- as(all.diff, "GRanges")

annotateWithFeatures(all.diffG,GTFsplit)

```
! GenomicTools is not supported in CRAN anymore


